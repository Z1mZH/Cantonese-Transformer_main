{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11abe3e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T06:01:32.601199Z",
     "start_time": "2025-01-12T06:01:23.500079200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([   1,    1,    0, 9178,   32,   47]),\n tensor([0, 0, 1, 1, 1, 1]),\n '<pad><pad><s>how are you')"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "from util import TokenizerUtil\n",
    "\n",
    "tokenizer = TokenizerUtil()\n",
    "\n",
    "input_ids, _ = tokenizer.encode('how are you', max_length=6)\n",
    "\n",
    "input_ids, attention_mask = tokenizer.pad_to_left(input_ids)\n",
    "\n",
    "input_ids, attention_mask, tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "835db30b",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-01-12T06:02:04.068486800Z",
     "start_time": "2025-01-12T06:02:01.750001400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/4375 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b463c7f595774643b71ac60eb08f0827"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(1093,\n {'input_ids': tensor([[    1,     1,     1,  ..., 45682,  6267,    35],\n          [    1,     1,     1,  ..., 11423,  6267,    35],\n          [    1,     1,     1,  ..., 45682,  6267,    35],\n          [    1,     1,     1,  ..., 45682,  6267,    35]]),\n  'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n          [0, 0, 0,  ..., 1, 1, 1],\n          [0, 0, 0,  ..., 1, 1, 1],\n          [0, 0, 0,  ..., 1, 1, 1]])})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "from datasets import load_dataset\n",
    "from transformers import default_data_collator\n",
    "\n",
    "dataset = load_dataset('json', data_files='dataset/train_new.json', split='train')\n",
    "\n",
    "#2,4,4切分,取最后一部分\n",
    "dataset = dataset.select(range(4400, len(dataset)))\n",
    "\n",
    "\n",
    "def f(data):\n",
    "    input_ids, _ = tokenizer.encode(data['prompt'], max_length=256)\n",
    "    input_ids, attention_mask = tokenizer.pad_to_left(input_ids)\n",
    "\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "\n",
    "dataset = dataset.map(f, remove_columns=dataset.column_names)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     collate_fn=default_data_collator,\n",
    "                                     batch_size=4,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "\n",
    "len(loader), next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7480ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T06:02:12.518479500Z",
     "start_time": "2025-01-12T06:02:08.458579400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c84cbe0fcc324f9d8b51040c18d7417e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count_require': 2.21044736, 'count_all': 14.29004288, 'ratio': 0.15468444556549854}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, get_scheduler\n",
    "import lora\n",
    "\n",
    "model_actor = AutoModelForCausalLM.from_pretrained('model/actor', dropout=0.0)\n",
    "lora.insert(model_actor)\n",
    "\n",
    "\n",
    "def f():\n",
    "    params = []\n",
    "    params_lora = []\n",
    "    for n, p in model_actor.named_parameters():\n",
    "        if not p.requires_grad:\n",
    "            continue\n",
    "        if 'lora_A' in n or 'lora_B' in n:\n",
    "            params_lora.append(p)\n",
    "            continue\n",
    "        params.append(p)\n",
    "\n",
    "    return [{\n",
    "        'params': params,\n",
    "        'weight_decay': 0.0\n",
    "    }, {\n",
    "        'params': params_lora,\n",
    "        'weight_decay': 0.0,\n",
    "        'lr': 5e-4\n",
    "    }]\n",
    "\n",
    "\n",
    "optimizer_actor = torch.optim.Adam(f(), lr=1e-5, betas=(0.9, 0.95))\n",
    "\n",
    "scheduler_actor = get_scheduler(name='cosine',\n",
    "                                optimizer=optimizer_actor,\n",
    "                                num_warmup_steps=100,\n",
    "                                num_training_steps=800)\n",
    "\n",
    "model_actor.gradient_checkpointing_enable()\n",
    "model_actor.train()\n",
    "\n",
    "lora.count_params(model_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd68dee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T06:02:15.644802900Z",
     "start_time": "2025-01-12T06:02:13.792856400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_63032\\2731563814.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_critic = torch.load('model/critic')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count_require': 3.31196928, 'count_all': 3.31196928, 'ratio': 1.0}\n"
     ]
    }
   ],
   "source": [
    "class CriticModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        from transformers import AutoModel\n",
    "        self.rwtransformer = AutoModel.from_pretrained('facebook/opt-350m',\n",
    "                                                       dropout=0.0)\n",
    "\n",
    "        self.v_head = torch.nn.Linear(512, 1, bias=False)\n",
    "\n",
    "    def get_value(self, input_ids, attention_mask):\n",
    "        value = self.rwtransformer(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask).last_hidden_state\n",
    "        return self.v_head(value).squeeze(2)\n",
    "\n",
    "    def get_reward(self, input_ids, attention_mask):\n",
    "        value = self.get_value(input_ids, attention_mask)\n",
    "\n",
    "        reward = []\n",
    "        for i, v in zip(input_ids, value):\n",
    "            end = input_ids.shape[1] - 1\n",
    "            if tokenizer.eos_token_id in i:\n",
    "                end = i.tolist().index(tokenizer.eos_token_id)\n",
    "            reward.append(v[end])\n",
    "        reward = torch.stack(reward)\n",
    "\n",
    "        return reward\n",
    "\n",
    "\n",
    "model_critic = torch.load('model/critic')\n",
    "\n",
    "optimizer_critic = torch.optim.Adam(model_critic.parameters(),\n",
    "                                    lr=5e-6,\n",
    "                                    betas=(0.9, 0.95))\n",
    "\n",
    "scheduler_critic = get_scheduler(name='cosine',\n",
    "                                 optimizer=optimizer_critic,\n",
    "                                 num_warmup_steps=100,\n",
    "                                 num_training_steps=800)\n",
    "\n",
    "model_critic.train()\n",
    "\n",
    "lora.count_params(model_critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b9d356",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T06:02:24.370219900Z",
     "start_time": "2025-01-12T06:02:17.399130900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3814e67e4704ce9adc649f1ed4bfe04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_63032\\2506966003.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_reward = torch.load('model/critic')\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "model_ref = AutoModelForCausalLM.from_pretrained('model/actor')\n",
    "model_reward = torch.load('model/critic')\n",
    "\n",
    "model_ref.eval()\n",
    "model_reward.eval()\n",
    "\n",
    "accelerator = Accelerator(gradient_accumulation_steps=1,\n",
    "                          mixed_precision='fp16')\n",
    "\n",
    "(loader, model_actor, optimizer_actor, scheduler_actor, model_critic,\n",
    " optimizer_critic,\n",
    " scheduler_critic) = accelerator.prepare(loader, model_actor, optimizer_actor,\n",
    "                                         scheduler_actor, model_critic,\n",
    "                                         optimizer_critic, scheduler_critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "787e283d",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-01-12T06:03:10.832693500Z",
     "start_time": "2025-01-12T06:02:24.373221800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "C:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "C:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\opt\\modeling_opt.py:452: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([4, 512])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def get_generate(input_ids, attention_mask):\n",
    "    generate = model_actor.generate(input_ids,\n",
    "                                    attention_mask=attention_mask,\n",
    "                                    max_length=512,\n",
    "                                    pad_token_id=tokenizer.pad_token_id,\n",
    "                                    eos_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    lens = (generate[:, 256:] != tokenizer.pad_token_id).sum(1)\n",
    "\n",
    "    return generate[lens > 1]\n",
    "\n",
    "\n",
    "data = next(iter(loader))\n",
    "\n",
    "get_generate(**data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8687059d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T06:03:57.532641300Z",
     "start_time": "2025-01-12T06:03:57.450090800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 123])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prob(prob, index):\n",
    "    prob = prob.log_softmax(dim=2)\n",
    "    prob = prob.gather(dim=2, index=index.unsqueeze(2))\n",
    "    return prob.squeeze(2)\n",
    "\n",
    "\n",
    "get_prob(torch.randn(4, 123, 999), torch.randint(0, 999, (4, 123))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d7d1d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T06:04:27.191461700Z",
     "start_time": "2025-01-12T06:03:59.441631800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([4, 512]),\n torch.Size([4, 512]),\n torch.Size([4, 511]),\n torch.Size([4, 511]),\n torch.Size([4, 511]),\n torch.Size([4]))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_generate = None\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_batch(input_ids, attention_mask):\n",
    "    #input_ids -> [4, 256]\n",
    "    #attention_mask -> [4, 256]\n",
    "    global last_generate\n",
    "\n",
    "    #根据问题生成回答\n",
    "    #[4, gen_lens]\n",
    "    generate = get_generate(input_ids, attention_mask)\n",
    "\n",
    "    #制作缓存,防止所有回答为空的情况\n",
    "    if len(generate):\n",
    "        last_generate = generate\n",
    "    else:\n",
    "        generate = last_generate\n",
    "\n",
    "    #[4, gen_lens]\n",
    "    generate_mask = (generate != tokenizer.pad_token_id).long()\n",
    "\n",
    "    #两个模型分别取回答被预测到的概率\n",
    "    #[4, gen_lens-1]\n",
    "    prob_old = model_actor(input_ids=generate,\n",
    "                           attention_mask=generate_mask).logits\n",
    "    prob_old = get_prob(prob_old[:, :-1], generate[:, 1:])\n",
    "\n",
    "    #取每个词的value\n",
    "    #[4, gen_lens-1]\n",
    "    value_old = model_critic.get_value(generate, generate_mask)[:, :-1]\n",
    "\n",
    "    #[4, gen_lens-1]\n",
    "    prob_ref = model_ref(\n",
    "        input_ids=generate.to('cpu'),\n",
    "        attention_mask=generate_mask.to('cpu')).logits.to('cuda')\n",
    "    prob_ref = get_prob(prob_ref[:, :-1], generate[:, 1:])\n",
    "\n",
    "    #取回答的分数\n",
    "    #[4]\n",
    "    reward = model_reward.get_reward(generate.to('cpu'),\n",
    "                                     generate_mask.to('cpu')).to('cuda')\n",
    "\n",
    "    return generate, generate_mask, prob_old, prob_ref, value_old, reward\n",
    "\n",
    "\n",
    "generate, generate_mask, prob_old, prob_ref, value_old, reward = get_batch(\n",
    "    **data)\n",
    "\n",
    "generate.shape, generate_mask.shape, prob_old.shape, prob_ref.shape, value_old.shape, reward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb227950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T06:04:40.507270400Z",
     "start_time": "2025-01-12T06:04:40.486826800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 511])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_reward_kl(end, prob_old, prob_ref, reward):\n",
    "    #prob_old -> [4, gen_lens-1]\n",
    "    #prob_ref -> [4, gen_lens-1]\n",
    "    #reward -> [4]\n",
    "\n",
    "    #两份预测概率求kl散度\n",
    "    #[4, gen_lens-1]\n",
    "    reward_kl = -0.1 * (prob_old - prob_ref)\n",
    "\n",
    "    #把原本的reward加在kl散度的最后一个字上\n",
    "    for i, e in enumerate(end):\n",
    "        if e >= reward_kl.shape[1]:\n",
    "            e = -1\n",
    "        reward_kl[i, e] += reward[i].clamp(-5, 5)\n",
    "\n",
    "    #[4, gen_lens-1]\n",
    "    return reward_kl\n",
    "\n",
    "\n",
    "end = generate_mask[:, 256:].sum(1) + 255\n",
    "end = end.tolist()\n",
    "\n",
    "reward_kl = get_reward_kl(end, prob_old, prob_ref, reward)\n",
    "\n",
    "reward_kl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf23aae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T06:04:47.493484200Z",
     "start_time": "2025-01-12T06:04:47.448174300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 256])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#解释见get_delta_note函数\n",
    "def get_delta(value_old, reward_kl):\n",
    "    #value_old -> [4, gen_lens-1]\n",
    "    #reward_kl -> [4, gen_lens-1]\n",
    "\n",
    "    #gen_lens-2 -> 255\n",
    "    delta = []\n",
    "    for i in reversed(range(255, value_old.shape[1])):\n",
    "        #[4]\n",
    "        value_next = 0.0\n",
    "        if i != value_old.shape[1] - 1:\n",
    "            value_next = value_old[:, i + 1]\n",
    "\n",
    "        #[4]\n",
    "        d = reward_kl[:, i] + value_next - value_old[:, i]\n",
    "        if len(delta):\n",
    "            d += 0.95 * delta[-1]\n",
    "        delta.append(d)\n",
    "\n",
    "    #[4, gen_lens-256]\n",
    "    delta = torch.stack(delta[::-1], dim=1)\n",
    "\n",
    "    return delta\n",
    "\n",
    "\n",
    "delta = get_delta(value_old, reward_kl)\n",
    "\n",
    "delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b1716c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T06:05:05.761439600Z",
     "start_time": "2025-01-12T06:04:49.944331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'test success'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_delta函数的原理解释,注释性代码\n",
    "#数学上和get_delta函数等价,但是运行效率低\n",
    "def get_delta_note(value_old, reward_kl):\n",
    "    #循环中自减会出问题,所以先clone一份再操作\n",
    "    clone = value_old.clone()\n",
    "\n",
    "    #下一个词的value,减去当前词的value,相当于对value去基线,缩小数值方差\n",
    "    #每个词的value是相互独立的,前后词value的差,可以视为预测质量的衡量\n",
    "    for i in range(255, value_old.shape[1]):\n",
    "        value_next = 0.0\n",
    "        if i != value_old.shape[1] - 1:\n",
    "            value_next = value_old[:, i + 1]\n",
    "        clone[:, i] = value_next - value_old[:, i]\n",
    "    value_old = clone\n",
    "\n",
    "    #在value中融合reward,kl\n",
    "    value_old += reward_kl\n",
    "\n",
    "    #蒙特卡洛采样法估计Q函数\n",
    "    #这里计算的其实就是adv\n",
    "    delta = []\n",
    "    for i in range(255, value_old.shape[1]):\n",
    "        s = 0\n",
    "        for j in range(i, value_old.shape[1]):\n",
    "            s += value_old[:, j] * 0.95**(j - i)\n",
    "        delta.append(s)\n",
    "\n",
    "    return torch.stack(delta, dim=1)\n",
    "\n",
    "\n",
    "#测试两个函数是等价的,误差是由于计算机精度导致的\n",
    "for i in range(1000):\n",
    "    value_old_test = torch.randn(4, 285)\n",
    "    reward_kl_test = torch.randn(4, 285)\n",
    "\n",
    "    diff = get_delta(value_old_test, reward_kl_test) - get_delta_note(\n",
    "        value_old_test, reward_kl_test)\n",
    "    diff = diff.abs().max().item()\n",
    "    assert diff < 1e-5\n",
    "'test success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf1bcf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T06:05:14.527035700Z",
     "start_time": "2025-01-12T06:05:14.480637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-0.0078, device='cuda:0')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_loss_actor(prob_new, prob_old, delta, generate_mask):\n",
    "    prob_new = prob_new[:, 255:]\n",
    "    prob_old = prob_old[:, 255:]\n",
    "    generate_mask = generate_mask[:, 256:]\n",
    "\n",
    "    #prob_new -> [4, gen_lens-256]\n",
    "    #prob_old -> [4, gen_lens-256]\n",
    "    #delta -> [4, gen_lens-256]\n",
    "    #generate_mask -> [4, gen_lens-256]\n",
    "\n",
    "    #对数概率,求差就是求商,所以这里求的是新旧概率的变化率\n",
    "    #[4, gen_lens-256]\n",
    "    ratio = ((prob_new - prob_old) * generate_mask).exp()\n",
    "\n",
    "    #delta是估计出来的去基线Q值,以变化率来缩放Q值\n",
    "    #最大化Q值,以此来寻找最优的actor\n",
    "    #裁剪,防止自举\n",
    "    #[4, gen_lens-256]\n",
    "    loss1 = delta * ratio\n",
    "    loss2 = delta * ratio.clamp(0.8, 1.2)\n",
    "    loss = torch.min(loss1, loss2) * generate_mask\n",
    "    loss = loss.sum() / generate_mask.sum() / 8\n",
    "    return -loss\n",
    "\n",
    "\n",
    "loss_actor = get_loss_actor(prob_old, prob_old, delta, generate_mask)\n",
    "\n",
    "loss_actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9a4db24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T06:05:17.625774700Z",
     "start_time": "2025-01-12T06:05:17.598245800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0350, device='cuda:0')"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_loss_critic(value_new, value_old, delta, generate_mask):\n",
    "    value_new = value_new[:, 255:]\n",
    "    value_old = value_old[:, 255:]\n",
    "    generate_mask = generate_mask[:, 256:]\n",
    "\n",
    "    #value_new -> [4, gen_lens-256]\n",
    "    #value_old -> [4, gen_lens-256]\n",
    "    #delta -> [4, gen_lens-256]\n",
    "    #generate_mask -> [4, gen_lens-256]\n",
    "\n",
    "    #delta是估计出来的去基线Q值,加上value_old后还原为Q值\n",
    "    #value_new和Q值求mse loss即可,因为value都是对Q函数的估计\n",
    "    #裁剪,防止自举\n",
    "    #[4, gen_lens-256]\n",
    "    loss1 = (value_new - delta - value_old)**2\n",
    "    value_new = value_new.clamp(value_old - 0.2, value_old + 0.2)\n",
    "    loss2 = (value_new - delta - value_old)**2\n",
    "\n",
    "    #求平均\n",
    "    loss = torch.max(loss1, loss2) * generate_mask\n",
    "    loss = loss.sum() / 2 / generate_mask.sum() / 8\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "loss_critic = get_loss_critic(value_old, value_old, delta, generate_mask)\n",
    "\n",
    "loss_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "825b4816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T06:05:23.620343800Z",
     "start_time": "2025-01-12T06:05:22.711240Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.00895870290696621, 0.03916715458035469)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(generate, generate_mask, prob_old, prob_ref, value_old, reward,\n",
    "          do_step):\n",
    "    #generate -> [4, gen_lens]\n",
    "    #generate_mask -> [4, gen_lens]\n",
    "    #prob_old -> [4, gen_lens-1]\n",
    "    #prob_ref -> [4, gen_lens-1]\n",
    "    #value_old -> [4, gen_lens-1]\n",
    "    #reward -> [4]\n",
    "    #do_step -> bool\n",
    "\n",
    "    #求出每句话结束的索引\n",
    "    #[4]\n",
    "    end = generate_mask[:, 256:].sum(1) + 255\n",
    "    end = end.tolist()\n",
    "\n",
    "    #结束以后的value归零\n",
    "    for i, e in enumerate(end):\n",
    "        value_old[i, e + 1:] = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        #计算新旧概率的kl散度,再把reward加在最后一个字上\n",
    "        #[4, gen_lens-1]\n",
    "        reward_kl = get_reward_kl(end, prob_old, prob_ref, reward)\n",
    "\n",
    "        #估计去基线的Q值\n",
    "        #[4, gen_lens-256]\n",
    "        delta = get_delta(value_old, reward_kl)\n",
    "\n",
    "    #重新计算回答被生成的概率\n",
    "    #[4, gen_lens-1]\n",
    "    prob_new = model_actor(input_ids=generate,\n",
    "                           attention_mask=generate_mask).logits\n",
    "    prob_new = get_prob(prob_new[:, :-1], generate[:, 1:])\n",
    "\n",
    "    #更新actor\n",
    "    loss_actor = get_loss_actor(prob_new, prob_old, delta, generate_mask)\n",
    "    accelerator.backward(loss_actor)\n",
    "    if do_step:\n",
    "        accelerator.clip_grad_norm_(\n",
    "            [i for i in model_actor.parameters() if i.requires_grad], 1.0)\n",
    "        optimizer_actor.step()\n",
    "        scheduler_actor.step()\n",
    "        optimizer_actor.zero_grad()\n",
    "\n",
    "    #重新计算每个词的value\n",
    "    #[4, gen_lens-1]\n",
    "    value_new = model_critic.get_value(input_ids=generate,\n",
    "                                       attention_mask=generate_mask)[:, :-1]\n",
    "\n",
    "    #更新critic\n",
    "    loss_critic = get_loss_critic(value_new, value_old, delta, generate_mask)\n",
    "    accelerator.backward(loss_critic)\n",
    "    if do_step:\n",
    "        accelerator.clip_grad_norm_(model_critic.parameters(), 1.0)\n",
    "        optimizer_critic.step()\n",
    "        scheduler_critic.step()\n",
    "        optimizer_critic.zero_grad()\n",
    "\n",
    "    return loss_actor.item(), loss_critic.item()\n",
    "\n",
    "\n",
    "train(generate, generate_mask, prob_old, prob_ref, value_old, reward, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bd3e547",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T06:33:42.251858600Z",
     "start_time": "2025-01-12T06:15:33.774230900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1093 0.018578283488750458 0.04839198291301727 1.0000000000000002e-06 5.000000000000001e-07\n",
      " 我差点撞到人</s>\n",
      "0.3820284605026245\n",
      "15 1093 -0.01576985791325569 0.03558586537837982 1.1e-06 5.5e-07\n",
      " 你给我滚！</s>\n",
      "0.38951095938682556\n",
      "23 1093 -0.04136982187628746 0.07322313636541367 1.2000000000000002e-06 6.000000000000001e-07\n",
      " 不要吃那些蛋糕啊！</s>\n",
      "0.01807314157485962\n",
      "31 1093 -0.03838038071990013 0.04951575770974159 1.3e-06 6.5e-07\n",
      " 所以说呢，不要总係人，会耽误事嘅。</s>\n",
      "0.3741348385810852\n",
      "39 1093 -0.025787414982914925 0.03457837179303169 1.4000000000000001e-06 7.000000000000001e-07\n",
      " 少女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女嘅女\n",
      "0.3361518979072571\n",
      "47 1093 -0.04514344409108162 0.03519841283559799 1.5e-06 7.5e-07\n",
      " 我走嘅奶故事里嘅森林</s>\n",
      "0.343353271484375\n",
      "55 1093 -0.026819337159395218 0.035187337547540665 1.6000000000000001e-06 8.000000000000001e-07\n",
      " 实情嘅</s>\n",
      "-0.36715489625930786\n",
      "63 1093 -0.041282568126916885 0.04793929308652878 1.7000000000000002e-06 8.500000000000001e-07\n",
      " 再吃碗粥吧</s>\n",
      "0.12167121469974518\n",
      "71 1093 -0.013404875062406063 0.03530661016702652 1.8000000000000001e-06 9.000000000000001e-07\n",
      " 我穿起来垮垮垮嘅，不适合我穿。</s>\n",
      "0.2775470018386841\n",
      "79 1093 -0.01639101840555668 0.029995011165738106 1.9000000000000002e-06 9.500000000000001e-07\n",
      " 不要表错情啊，我係你啊。</s>\n",
      "0.049605488777160645\n",
      "87 1093 0.006351071409881115 0.027585798874497414 2.0000000000000003e-06 1.0000000000000002e-06\n",
      " 很多人排队</s>\n",
      "0.01767328381538391\n",
      "95 1093 0.015095571056008339 0.026729486882686615 2.1000000000000002e-06 1.0500000000000001e-06\n",
      " 但我们现在知道，缺氧也係其中一个原因。</s>\n",
      "0.5934590101242065\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(loader):\n",
    "    #生成数据\n",
    "    (generate, generate_mask, prob_old, prob_ref, value_old,\n",
    "     reward) = get_batch(**data)\n",
    "\n",
    "    do_step = (i + 1) % 8 == 0\n",
    "\n",
    "    #训练\n",
    "    loss_actor, loss_critic = train(generate, generate_mask, prob_old,\n",
    "                                    prob_ref, value_old, reward, do_step)\n",
    "\n",
    "    if do_step:\n",
    "        lr_actor = optimizer_actor.param_groups[0]['lr']\n",
    "        lr_critic = optimizer_critic.param_groups[0]['lr']\n",
    "        print(i, len(loader), loss_actor, loss_critic, lr_actor, lr_critic)\n",
    "        print(tokenizer.decode(generate[0, 256:]))\n",
    "        print(reward[0].item())\n",
    "\n",
    "    if i >= 100:\n",
    "        break\n",
    "\n",
    "lora.merge(model_actor)\n",
    "model_actor.save_pretrained('model/rlhf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
